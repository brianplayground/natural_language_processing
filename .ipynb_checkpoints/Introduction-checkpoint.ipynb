{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is an amazing sentance. This is another amazing sentence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is an amazing sentance.', 'This is another amazing sentence']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize by sentence\n",
    "sents = sent_tokenize(text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'sentance',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'another',\n",
       " 'amazing',\n",
       " 'sentence']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize by word\n",
    "words = word_tokenize(text)\n",
    "words\n",
    "# ['This', 'is','an', 'amazing','sentance', '.', 'This', 'is', 'another', 'amazing', 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "# stop words are words that dont add much meaning to a sentence or text e.g 'are', 'is', 'as'\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "customStopWords = set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'amazing', 'sentance', 'This', 'another', 'amazing', 'sentence']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_with_not_stop_words = [word for word in word_tokenize(text) if word not in customStopWords]\n",
    "words_with_not_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('This', 'amazing'), 1),\n",
       " (('This', 'another'), 1),\n",
       " (('amazing', 'sentance'), 1),\n",
       " (('amazing', 'sentence'), 1),\n",
       " (('another', 'amazing'), 1),\n",
       " (('sentance', 'This'), 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams and N grams\n",
    "# getting the frequency of words in a document\n",
    "from nltk.collections import * \n",
    "bigrams_measure = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(words_with_not_stop_words)\n",
    "sorted(finder.ngram_fd.items()) # print the bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steaming and parts of speech tagging\n",
    "# using the lancaster steaming algorithim\n",
    "from nltk.stem.lancaster import LancasterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_text = \"you are cool, but are you cooler than the kid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'ar', 'cool', ',', 'but', 'ar', 'you', 'cool', 'than', 'the', 'kid']\n"
     ]
    }
   ],
   "source": [
    "ls= LancasterStemmer()\n",
    "stemmed_words=[ls.stem(word) for word in word_tokenize(cool_text) ]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('cool', 'JJ'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('cooler', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('kid', 'NN')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(cool_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disambiguating\n",
    "# this is the process of understanding the meaning of a world in relation to context used\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cold.n.01') a mild viral infection involving the nose and respiratory passages (but not the lungs)\n",
      "Synset('coldness.n.03') the absence of heat\n",
      "Synset('cold.n.03') the sensation produced by low temperatures\n",
      "Synset('cold.a.01') having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration\n",
      "Synset('cold.a.02') extended meanings; especially of psychological coldness; without human warmth or emotion\n",
      "Synset('cold.s.03') having lost freshness through passage of time\n",
      "Synset('cold.s.04') (color) giving no sensation of warmth\n",
      "Synset('cold.s.05') marked by errorless familiarity\n",
      "Synset('cold.s.06') lacking originality or spontaneity; no longer new\n",
      "Synset('cold.s.07') so intense as to be almost uncontrollable\n",
      "Synset('cold.s.08') sexually unresponsive\n",
      "Synset('cold.s.09') without compunction or human feeling\n",
      "Synset('cold.s.10') feeling or showing no enthusiasm\n",
      "Synset('cold.s.11') unconscious from a blow or shock or intoxication\n",
      "Synset('cold.s.12') of a seeker; far from the object sought\n",
      "Synset('cold.s.13') lacking the warmth of life\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets('cold'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cold.a.01') having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration\n"
     ]
    }
   ],
   "source": [
    "s1 = lesk(word_tokenize(\"I am cold\"),'cold')\n",
    "print(s1, s1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cold.s.07') so intense as to be almost uncontrollable\n"
     ]
    }
   ],
   "source": [
    "s2 = lesk(word_tokenize(\"she is so cold towards me\"),'cold')\n",
    "print(s2, s2.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
